import csv
import numpy as np
from math import sqrt

##### Debugging controller ========================================================================
_DISPLAY = 1

##### Number of iterations ========================================================================
ITERATION = 0

##### Parameters ==================================================================================
# Null
w_list = [0 for x in range(163)]

# Error : 5.680020830254354
w_list = [0.38132943356955951, 0.062808749660005408, -0.13922233353111979, 0.18170138506576972, -0.26480157330924881, -0.005032079248562471, 0.15905738631419158, -0.065149697097637738, -0.26685074267931397, 0.32372604776840624, -2.3030318992441146, 1.1935388720395634, 0.70220480989171907, 0.67302100015594934, 0.10102544927625523, -0.20758250043588866, -1.4689490800493932, 1.216428550733295, 4.0693475050427539, 0.1640112551180094, -0.085334162000571645, 0.19428413769671282, -0.49744964031436356, 0.46479231791726205, -0.067953827338914752, -0.51496911334255902, 0.24691865127822488, 1.2427477985828173, -2.8047243985324153, 3.7875155475871076, -2.4228641023143958, 2.6949674911310604, 3.299475291808843, -4.8368047994707641, 0.72803747993354051, 1.5855207925039587, 0.72086222986260573, 0.045774241955808759, 0.041694000486679483, 0.10365235105998133, -0.43559597115794413, -0.21771346382467982, -0.25103192705531407, -0.027797249990138884, -0.24883990714012749, -0.29688168740071497, 0.049723139467705041, -0.019954547032208947, -0.038618819099211943, -0.42937175222425994, -0.25025879143363483, -0.16499828571896974, -0.10080664663353578, -0.44816889022393469, 0.027580320430247884, -0.0077457024310639833, -0.063853015543991698, 0.023748543879379524, 0.40309602038184145, 0.2292808143441481, 0.1771292460732995, 0.04985173585093533, 0.35529424612457977, 0.24962388846455552, -0.00012315797040349241, 0.014577199367478408, -0.010747201708887488, -0.01902784348398362, 0.0015910102135519855, -0.033613297597199443, -0.019761373106298205, -0.013922940509352985, 0.098185581501124608, 0.008659885176739622, 0.008963982437311644, -0.030535021013138743, 0.043027982301726331, -0.0080906403137971771, -0.039311028652022753, 0.039020784063714765, -0.0024569407633065823, 0.034912614845059337, -0.035904930752173478, -0.01292078690985797, 0.21478481529386712, -0.2358763771442195, -0.021174120674946721, 0.49174771580695742, -0.55597365864888393, 0.024299319560324058, 0.95286613866560288, 0.037428781266736329, -0.0093290833668826997, -0.046006617107717744, 0.0099767169909196832, -0.056369841148562909, 0.048916402113182787, 0.017663168587671897, -0.040554240495170785, -0.077935655002107126, -0.0089201761930854731, 0.019184767201954653, 0.024520682490163315, -0.061392751595414144, -0.044925179490703356, 0.084276204479636352, -0.093537438473236409, -0.00012574871425635736, 0.052035513878499286, -0.28580384983003304, 0.33209665579273906, -0.074194868821179205, -0.054011735132703964, -0.0080665569194571241, 0.053776742242878317, -0.1144649824286248, 0.14208635891511945, 0.1463484678846308, 1.6993026533307507, -1.8365385534921814, 0.74527916165221963, -2.2537539043833026, -0.64504584340606019, 1.8573014327152473, 0.46960906378006495, -1.8416578343751668, -0.78448364240331836, -0.00045889069075197081, 0.0030201931222356938, -0.00031232489176474853, 0.0018696921519060342, 0.00045726356681367484, 0.0017932851817203126, -0.0025263624151759768, 0.0011978634227651161, 0.00027410523607760058, -0.0020571023436330048, -0.0010472110951498239, 0.00085371422902793571, -0.0018953171622424082, 0.00038467397690506973, -2.2358258953182782e-05, -2.446497125807752e-05, -0.0023979394753580298, 0.00044318327551520808, -0.17999551209201936, -0.13035638848607956, 0.23814983058570832, 0.078045435291671128, -0.098225133809905607, -0.075375592681120707, -0.032259260961926495, -0.0039476717249105342, -0.12480472728231429, -0.015382425612356809, 0.17607564683788512, -0.13658263615284333, -0.21751535013229031, -0.052153862649225058, 0.3370848275642821, -0.0042356930083022395, -0.31714649010632706, 0.19854301888444942]

# Gradients
w_grad = [0 for x in range(163)]

# Root-sum-square of gradients over time
w_grad_rms = [0 for x in range(163)]

# Regulation
lamda = 0

# Learning rates
w_lr = [0.001] + [0.001 for x in range(162)]
##### Variables ===================================================================================
data = [[[] for arg in range(18)] for month in range(12)]
x_list = []
y_list = []
err = 0
err_ss = 0
min_err = 0
w_best = []

##### Read in the training file ===================================================================
with open('train.csv', encoding='mac_roman', newline = '') as csv_file:
	# Read the file and delete the first line
	csv_obj = csv.reader(csv_file)
	all_data = list(csv_obj)
	del all_data[0]
	# Setting data (18 X 5760 array)
	for month in range(12):
		for day in range(20):
			for hour in range(24):
				for arg in range(18):
					if(all_data[18*(20*month+day)+arg][hour+3] == 'NR'):
						data[month][arg].append(0)
					else:
						data[month][arg].append(float(all_data[18*(20*month+day)+arg][hour+3]))
for month in range(12):
	for index in range(471):
		tmplist = [1]
		for arg in range(18):
			tmplist += [data[month][arg][index+x] for x in range(9)]
		x_list.append(tmplist)
		y_list.append([data[month][9][index+9]])

x = np.array(x_list)
y = np.array(y_list)
xt = x.transpose()
w = np.dot(np.dot(np.linalg.inv(np.dot(xt, x)), xt), y)

w_list = [w[x][0] for x in range(163)]
print(w_list)
##### Train with regulation =======================================================================
for it in range(ITERATION):
	if(_DISPLAY == 1 and it % 10 == 0):
		print("Iteration : ", it, " / ", ITERATION)
	w_grad = [0 for x in range(163)]
	for row in range(len(x_list)):
		xsum = 0
		for x in range(163):
			xsum += w_list[x] * x_list[row][x]
		w_grad = [w_grad[x] - 2 * x_list[row][x] * (y_list[row][0] - xsum) + 2 * lamda * w_list[x] for x in range(163)]
	w_grad_rms = [sqrt(pow(w_grad_rms[x], 2) + pow(w_grad[x], 2)).real for x in range(163)]
	w_list = [w_list[x] - w_lr[x] * w_grad[x] / w_grad_rms[x] for x in range(163)]

	if(_DISPLAY == 1 and it % 10 == 0):
		err_ss = 0
		for row in range(len(x_list)):
			xsum = 0
			for x in range(163):
				xsum += w_list[x] * x_list[row][x]
			err_ss += pow(y_list[row][0] - xsum, 2)
		err = sqrt(err_ss/len(x_list)).real
		if(it == 0 or err < min_err):
			min_err = err
			w_best = w_list
			print("w : ", w_list)
		print("Error : ", err)

err_ss = 0
for row in range(len(x_list)):
	xsum = 0
	for x in range(163):
		xsum += w_list[x] * x_list[row][x]
	err_ss += pow(y_list[row][0] - xsum, 2)
err = sqrt(err_ss/row).real
print('Error : ', err)























