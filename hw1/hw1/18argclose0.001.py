import csv
import numpy as np
from math import sqrt

##### Debugging controller ========================================================================
_DISPLAY = 1

##### Number of iterations ========================================================================
ITERATION = 10000

##### Parameters ==================================================================================
# Null
w_list = [0 for x in range(163)]

# Error : 5.679527710411573
w_list = [0.37946142765339047, 0.06177397653212266, -0.1383890232358124, 0.18051395176401763, -0.26390259588582038, -0.004091283784780908, 0.1579287249865593, -0.064238893168954952, -0.26588202303872754, 0.32260259822036774, -2.2991740605789364, 1.1910448580071671, 0.70035796419289109, 0.67117849127309726, 0.099897157589139987, -0.20634671305619229, -1.4661565303324338, 1.2138956979303095, 4.0633161180382187, 0.16245808437442727, -0.084428124220288558, 0.19250668662739037, -0.49405394359142091, 0.46168503578566444, -0.06702793532503859, -0.51127675383302695, 0.24634577201306984, 1.2376502539147776, -2.7659186677066869, 3.7366348762628929, -2.3890031867479564, 2.6587259862551904, 3.2558062150297959, -4.7748045234109364, 0.71735754691136033, 1.5640458924545351, 0.71188528778242599, 0.045258545166246958, 0.040718776479215853, 0.10425159045653361, -0.43378564970312355, -0.21651667111965889, -0.25009130337326513, -0.027110858400438642, -0.24796692562990552, -0.2962581153025669, 0.048497928034965054, -0.019766162170161253, -0.037722316944325249, -0.4283726823077072, -0.24937705490791431, -0.16383258933544759, -0.099872249727118251, -0.44674190412321901, 0.027671861368011995, -0.0068796197916018483, -0.063490729887185751, 0.022982527289933274, 0.40206864513268264, 0.2281556829299575, 0.17617013210176818, 0.048723320619212189, 0.35447851196399127, 0.24937109230609938, 0.00029298194841006158, 0.014010332449084763, -0.010605452062769301, -0.018757938325215221, 0.001090148878872349, -0.033298611669649945, -0.019863462404116339, -0.0134986336128775, 0.09782994084645584, 0.0085097096482631245, 0.0089860192565080696, -0.030147795152133349, 0.042475291113012195, -0.0078436187177172885, -0.039015336972318931, 0.038512775346977571, -0.0021964607883367864, 0.034915885406854107, -0.035842911140406136, -0.012638019351656203, 0.21403260846352076, -0.23523126571710978, -0.021020078799007743, 0.49093661253142745, -0.55527375366650211, 0.024119642376677984, 0.95276372330684955, 0.037158181127186482, -0.0089291460386837981, -0.045964635003419872, 0.0096737804117028002, -0.056066341124848332, 0.048832549344007964, 0.017531676757023332, -0.040644422796765556, -0.077660923316016151, -0.0080567022756352392, 0.018289927650519684, 0.023657984466375084, -0.060554340706003275, -0.044231371924125643, 0.083138644146443286, -0.092766984632084201, 0.0006477269742424384, 0.051036504031663037, -0.28506135717443631, 0.33061986536556748, -0.07387082810192179, -0.053678887428557427, -0.0075483893781201801, 0.053033994134730707, -0.11364744543839611, 0.14152274201638032, 0.14640280354087212, 1.6963184480397291, -1.833404984669553, 0.74345315386122934, -2.2500891659779052, -0.64317382789764843, 1.854166271418328, 0.46809696331151007, -1.838442353771518, -0.78237040677336567, -0.00045369874635048797, 0.003025359431722809, -0.00032097704467424826, 0.0018722954386865857, 0.00045651803075264722, 0.0017882419674456463, -0.002528201466725331, 0.0012011516755913942, 0.00027241142753016998, -0.0020568537120168227, -0.0010470177446510395, 0.00084977955448117305, -0.0018948099895596477, 0.00038456728145613091, -2.3953525387418066e-05, -2.6169551524469476e-05, -0.0023968147679249434, 0.00044190784863712814, -0.17926926426630821, -0.12956060131755251, 0.236825864099178, 0.076848462716304328, -0.097486591188486654, -0.074982194495281124, -0.032177647741522687, -0.0038449323524453959, -0.12417769775493784, -0.015033081136202843, 0.17484696205964176, -0.13576826336410169, -0.21649527901892898, -0.051352921077801685, 0.33550985403487782, -0.0040481988986599514, -0.31632640988773036, 0.19732603378073549]

# Gradients
w_grad = [0 for x in range(163)]

# Root-sum-square of gradients over time
w_grad_rms = [0 for x in range(163)]

# Regulation
lamda = 0.001

# Learning rates
w_lr = [0.05] + [0.01 for x in range(162)]
##### Variables ===================================================================================
data = [[[] for arg in range(18)] for month in range(12)]
x_list = []
y_list = []
err = 0
err_ss = 0
min_err = 0
w_best = []

##### Read in the training file ===================================================================
with open('train.csv', encoding='mac_roman', newline = '') as csv_file:
	# Read the file and delete the first line
	csv_obj = csv.reader(csv_file)
	all_data = list(csv_obj)
	del all_data[0]
	# Setting data (18 X 5760 array)
	for month in range(12):
		for day in range(20):
			for hour in range(24):
				for arg in range(18):
					if(all_data[18*(20*month+day)+arg][hour+3] == 'NR'):
						data[month][arg].append(0)
					else:
						data[month][arg].append(float(all_data[18*(20*month+day)+arg][hour+3]))
for month in range(12):
	for index in range(471):
		tmplist = [1]
		for arg in range(18):
			tmplist += [data[month][arg][index+x] for x in range(9)]
		x_list.append(tmplist)
		y_list.append([data[month][9][index+9]])

x = np.array(x_list)
y = np.array(y_list)
xt = x.transpose()
w = np.dot(np.dot(np.linalg.inv(np.dot(xt, x)), xt), y)

w_list = [w[x][0] for x in range(163)]
#print(w_list)
##### Train with regulation =======================================================================
for it in range(ITERATION):
	if(_DISPLAY == 1 and it % 10 == 0):
		print("Iteration : ", it, " / ", ITERATION)
	w_grad = [0 for x in range(163)]
	for row in range(len(x_list)):
		xsum = 0
		for x in range(163):
			xsum += w_list[x] * x_list[row][x]
		w_grad = [w_grad[x] - 2 * x_list[row][x] * (y_list[row][0] - xsum) + 2 * lamda * w_list[x] for x in range(163)]
	w_grad_rms = [sqrt(pow(w_grad_rms[x], 2) + pow(w_grad[x], 2)).real for x in range(163)]
	w_list = [w_list[x] - w_lr[x] * w_grad[x] / w_grad_rms[x] for x in range(163)]

	if(_DISPLAY == 1 and it % 10 == 0):
		err_ss = 0
		for row in range(len(x_list)):
			xsum = 0
			for x in range(163):
				xsum += w_list[x] * x_list[row][x]
			err_ss += pow(y_list[row][0] - xsum, 2)
		err = sqrt(err_ss/len(x_list)).real
		if(it == 0 or err < min_err):
			min_err = err
			w_best = w_list
			print("w : ", w_list)
		print("Error : ", err)
'''
err_ss = 0
for row in range(len(x_list)):
	xsum = 0
	for x in range(163):
		xsum += w_list[x] * x_list[row][x]
	err_ss += pow(y_list[row][0] - xsum, 2)
err = sqrt(err_ss/row).real
print('Error : ', err)
'''






















